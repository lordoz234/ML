{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled29.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNBaoYATCje2hKpcMJt/I7U",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lordoz234/ML/blob/master/Untitled29.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2v1yDsinxoyG"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQzGBUYexrY-"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "import csv\n",
        "from tqdm import tqdm_notebook\n",
        "from networkx.algorithms import approximation as approx\n",
        "from networkx.algorithms import bipartite\n",
        "from networkx.algorithms import tournament\n",
        "from networkx.algorithms import community\n",
        "from sklearn import preprocessing\n",
        "from statistics import mean, median_high, variance, median\n",
        "from numpy import linalg as LA\n",
        "\n",
        "templ = 0\n",
        "path = os.listdir('/content/drive/My Drive/files')\n",
        "os.chdir('/content/drive/My Drive/')\n",
        "\n",
        "d1 = dict()\n",
        "d = dict()\n",
        "d2 = dict()\n",
        "\n",
        "with open('/content/drive/My Drive/subjects_info.txt', 'r') as f:\n",
        "    data = f.read().splitlines()\n",
        "\n",
        "for temp in data:\n",
        "    inp = temp.split('\\t')\n",
        "    d1[inp[0] + '.txt'] = inp[1]\n",
        "    d2[inp[0] + '.txt'] = inp[2]\n",
        "\n",
        "\n",
        "def expected(a):\n",
        "    temp = 1/len(a)\n",
        "    sum = 0\n",
        "    for i in a:\n",
        "        sum += temp*i\n",
        "    return sum\n",
        "\n",
        "os.chdir('files/')\n",
        "k = 0\n",
        "r = 0\n",
        "a = []\n",
        "t = []\n",
        "ll = 0\n",
        "t.append('files')\n",
        "t.append('population')\n",
        "t.append('super_population')\n",
        "t.append('average_shortest_path_length')\n",
        "t.append('s_metric')\n",
        "t.append('wiener_index')\n",
        "t.append('graph_number_of_cliques')\n",
        "\n",
        "t.append('single_source_shortest_path_length_max_min')\n",
        "t.append('single_source_shortest_path_length_median')\n",
        "t.append('single_source_shortest_path_length_average')\n",
        "t.append('single_source_shortest_path_length_mean')\n",
        "t.append('single_source_shortest_path_length_std')\n",
        "t.append('single_source_shortest_path_length_var')\n",
        "t.append('single_source_shortest_path_length_expected')\n",
        "\n",
        "t.append('degrees_max_min')\n",
        "t.append('degrees_median')\n",
        "t.append('degrees_average')\n",
        "t.append('degrees_mean')\n",
        "t.append('degrees_std')\n",
        "t.append('degrees_var')\n",
        "t.append('degrees_expected')\n",
        "\n",
        "t.append('bc_max_min')\n",
        "t.append('bc_median')\n",
        "t.append('bc_average')\n",
        "t.append('bc_mean')\n",
        "t.append('bc_std')\n",
        "t.append('bc_var')\n",
        "t.append('bc_expected')\n",
        "\n",
        "t.append('rc_max_min')\n",
        "t.append('rc_average')\n",
        "t.append('rc_mean')\n",
        "t.append('rc_std')\n",
        "t.append('rc_var')\n",
        "t.append('rc_expected')\n",
        "\n",
        "a.append(t)\n",
        "for files in tqdm_notebook(path):\n",
        "    G = nx.Graph()\n",
        "    filename, file_extension = os.path.splitext(files)\n",
        "    if file_extension != '.txt':\n",
        "        continue\n",
        "    with open(files, 'r') as f:\n",
        "        data = f.read().splitlines()\n",
        "    if d2[files] == \"AFR\":\n",
        "        for i in range(len(data)):\n",
        "            temp = data[i].split(':')\n",
        "            if data[i][0] == 'M' and data[i][1] == 'T' and data[i][2] == '-':\n",
        "                continue\n",
        "            if len(temp) == 0 or len(temp) == 1:\n",
        "                continue\n",
        "            edj = temp[0]\n",
        "            temps = temp[1]\n",
        "            edjes = temps.split(',')\n",
        "            if edjes[0] == '':\n",
        "                continue\n",
        "            d[edj] = d.get(edj, 0)\n",
        "            if d[edj] == 0:\n",
        "                k += 1\n",
        "                d[edj] = k\n",
        "            for e in edjes:\n",
        "                d[e] = d.get(e, 0)\n",
        "                if d[e] == 0:\n",
        "                    k += 1\n",
        "                    d[e] = k\n",
        "                G.add_edge(d[edj], d[e])\n",
        "        tt = []\n",
        "        tt.append(files)\n",
        "        tt.append(d1[files])\n",
        "        tt.append(d2[files])\n",
        "        tt.append(nx.average_shortest_path_length(G))\n",
        "        tt.append(nx.s_metric(G,normalized=False))\n",
        "        tt.append(nx.wiener_index(G))\n",
        "        tt.append(nx.graph_number_of_cliques(G))\n",
        "        \n",
        "        single =  [val for (node, val) in nx.single_source_shortest_path_length(G, 1).items()]\n",
        "        tt.append(np.amax(single) - np.amin(single))\n",
        "        tt.append(np.nanmedian(single))\n",
        "        tt.append(np.average(single))\n",
        "        tt.append(np.nanmean(single))\n",
        "        tt.append(np.nanstd(single))\n",
        "        tt.append(np.nanvar(single))\n",
        "        tt.append(expected(single))\n",
        "        \n",
        "        degrees = [val for (node, val) in G.degree()]\n",
        "        tt.append(np.amax(degrees) - np.amin(degrees))\n",
        "        tt.append(np.nanmedian(degrees))\n",
        "        tt.append(np.average(degrees))\n",
        "        tt.append(np.nanmean(degrees))\n",
        "        tt.append(np.nanstd(degrees))\n",
        "        tt.append(np.nanvar(degrees))\n",
        "        tt.append(expected(degrees))\n",
        "\n",
        "        bc = [val for (node, val) in nx.betweenness_centrality(G).items()]\n",
        "        tt.append(np.amax(bc) - np.amin(bc))\n",
        "        tt.append(np.nanmedian(bc))\n",
        "        tt.append(np.average(bc))\n",
        "        tt.append(np.nanmean(bc))\n",
        "        tt.append(np.nanstd(bc))\n",
        "        tt.append(np.nanvar(bc))\n",
        "        tt.append(expected(bc))\n",
        "\n",
        "        rc = [val for (node, val) in nx.rich_club_coefficient(G,normalized=False).items()]\n",
        "\n",
        "        tt.append(np.amax(rc) - np.amin(rc))\n",
        "        tt.append(np.average(rc))\n",
        "        tt.append(np.nanmean(rc))\n",
        "        tt.append(np.nanstd(rc))\n",
        "        tt.append(np.nanvar(rc))\n",
        "        tt.append(expected(rc))\n",
        "        a.append(tt)\n",
        "\n",
        "for i in range(3, 34):\n",
        "    raw = [row[i] for row in a[1:]]\n",
        "    norm = [float(j)/max(raw) for j in raw]\n",
        "    yy = 0\n",
        "    for j in range(1, len(a)):\n",
        "        a[j][i] = norm[yy]\n",
        "        yy += 1\n",
        "with open('data_AFR_new.csv', 'w') as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "\n",
        "    for row in a:\n",
        "        writer.writerow(row)\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}